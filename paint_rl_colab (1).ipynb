{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5c1678e",
      "metadata": {
        "id": "f5c1678e"
      },
      "source": [
        "#REINFORCEMENT LEARNING FOR AUTONOMUS PAINTING USING MULTI OBJECTIVE REWARD FUNCTIONS\n",
        "#Three Painting Modes\n",
        "\n",
        "This notebook extends the beginner Paint-RL project with three painting modes:\n",
        "\n",
        "1. **Paint-by-number** — agent fills semantic/quantized color regions (region-fill actions).\n",
        "2. **Stylization** — agent tries to produce a painterly version of a photo; reward uses a simplified perceptual-ish loss (VGG is optional, but kept lightweight here).\n",
        "3. **Contour reconstruction** — agent learns to draw the object's edges/outlines.\n",
        "\n",
        "\n",
        "The notebook uses small images (32×32) for fast experimentation. Upload an image where applicable, or use auto-generated targets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4bbd416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4bbd416",
        "outputId": "66bc645f-8e69-4c4f-bd99-e7fb96322189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages: torch, torchvision, pillow, imageio, matplotlib, scikit-image, scikit-learn\n"
          ]
        }
      ],
      "source": [
        "# DL framework, img and gif r/w, kmeans\n",
        "!pip install -q torch torchvision pillow imageio matplotlib scikit-image scikit-learn\n",
        "\n",
        "print('Installed packages: torch, torchvision, pillow, imageio, matplotlib, scikit-image, scikit-learn')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16a30f4",
      "metadata": {
        "id": "f16a30f4"
      },
      "source": [
        "## Upload a target image\n",
        "\n",
        "Upload an image to use as the target for modes that need it (paint-by-number, stylization, contour). If you don't upload, demo circle/shape targets are generated automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e9debc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "a5e9debc",
        "outputId": "c2a38d62-842c-4c91-9764-a0bba7e0b460"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acc72eb7-49ef-41af-8f2d-3c1830886ada\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acc72eb7-49ef-41af-8f2d-3c1830886ada\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#upload files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "TARGET_IMAGE_PATH = None\n",
        "if uploaded:\n",
        "    TARGET_IMAGE_PATH = list(uploaded.keys())[0]\n",
        "    print('Uploaded:', TARGET_IMAGE_PATH)\n",
        "else:\n",
        "    print('No upload detected. Notebook will use generated targets where needed.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866bd255",
      "metadata": {
        "id": "866bd255"
      },
      "source": [
        "## Choose a mode\n",
        "\n",
        "Set `MODE` to one of: `'paint_by_number'`, `'stylization'`, `'contour'`, `'creative'`. Default in the example below is `'paint_by_number'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a0656f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20a0656f",
        "outputId": "c9432be2-9262-46e1-83ba-46d22d8c97a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter mode (paint_by_number / stylization / contour): contour\n",
            "MODE = contour\n"
          ]
        }
      ],
      "source": [
        "# User input for mode\n",
        "MODE = input(\"Enter mode (paint_by_number / stylization / contour): \").strip().lower()\n",
        "\n",
        "# Validate\n",
        "valid_modes = [\"paint_by_number\", \"stylization\", \"contour\"]\n",
        "\n",
        "if MODE not in valid_modes:\n",
        "    print(\"Invalid mode! Defaulting to 'paint_by_number'.\")\n",
        "    MODE = \"paint_by_number\"\n",
        "\n",
        "print(\"MODE =\", MODE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b968eba",
      "metadata": {
        "id": "8b968eba"
      },
      "outputs": [],
      "source": [
        "# img- resize, draw- canvas,strokes filter- blur\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "from skimage import color, filters\n",
        "import math\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "def load_and_resize(path_or_pil, size=32):\n",
        "    if isinstance(path_or_pil, str):\n",
        "        img = Image.open(path_or_pil).convert('RGB')\n",
        "    else:\n",
        "        img = path_or_pil.convert('RGB')\n",
        "    img = img.resize((size, size), Image.BILINEAR) #32x32, smooth img\n",
        "    return np.array(img).astype(np.float32) / 255.0\n",
        "\n",
        "def quantize_colors(img, n_colors=6, seed=0):\n",
        "    h,w,c = img.shape #hight, width, channel\n",
        "    arr = img.reshape(-1,3) #2D into 1D\n",
        "    km = KMeans(n_clusters=n_colors, random_state=seed).fit(arr) #label label 0to5\n",
        "    labels = km.labels_.reshape(h,w)\n",
        "    palette = km.cluster_centers_\n",
        "    quant = palette[labels]\n",
        "    return quant, labels, palette\n",
        "\n",
        "def edge_map(img_gray):\n",
        "    edges = filters.sobel(img_gray)\n",
        "    edges = (edges - edges.min()) / (edges.max() - edges.min() + 1e-8) #normalize to 0-1, cal reward, avoid div 0\n",
        "    return edges\n",
        "\n",
        "def symmetry_score(canvas):\n",
        "    h,w,c = canvas.shape #hue, satu, value\n",
        "    left = canvas[:, :w//2, :]\n",
        "    right = canvas[:, w - (w//2):, :]\n",
        "    right_flipped = np.flip(right, axis=1)\n",
        "    score = -np.mean((left - right_flipped)**2) #mirror\n",
        "    return score\n",
        "\n",
        "from skimage import color as skcolor\n",
        "\n",
        "def hue_std_score(canvas):\n",
        "    hsv = skcolor.rgb2hsv(np.clip(canvas, 0, 1))\n",
        "    hue = hsv[:,:,0]\n",
        "    return -float(np.std(hue)) #var high, std high, reward low\n",
        "\n",
        "from skimage import filters as skfilters\n",
        "\n",
        "def contrast_score(canvas):\n",
        "    gray = skcolor.rgb2gray(np.clip(canvas,0,1)) #pixel value remains in valid range, grey scale\n",
        "    mag = np.sqrt(skfilters.sobel_h(gray)**2 + skfilters.sobel_v(gray)**2) #sobel edge horizontal n verti edge detect\n",
        "    return float(np.mean(mag)) #mean high sharp, low smooth\n",
        "\n",
        "class PaintEnvMulti:\n",
        "    def __init__(self, mode='paint_by_number', target=None, canvas_size=32, max_steps=30, n_regions=6):\n",
        "        self.mode = mode\n",
        "        self.canvas_size = canvas_size\n",
        "        self.max_steps = max_steps\n",
        "        self.n_regions = n_regions\n",
        "        if target is None:\n",
        "            if mode in ('paint_by_number','stylization'):\n",
        "                tgt = Image.new('RGB',(canvas_size,canvas_size),(255,255,255))\n",
        "                d = ImageDraw.Draw(tgt); d.ellipse((6,6,26,26), fill=(200,50,50))\n",
        "                self.target = np.array(tgt).astype(np.float32)/255.0\n",
        "            elif mode == 'contour':\n",
        "                tgt = Image.new('RGB',(canvas_size,canvas_size),(255,255,255))\n",
        "                d = ImageDraw.Draw(tgt); d.ellipse((6,6,26,26), outline=(0,0,0), width=2)\n",
        "                self.target = np.array(tgt).astype(np.float32)/255.0\n",
        "            else:\n",
        "                self.target = None\n",
        "        else:\n",
        "            self.target = load_and_resize(target, size=canvas_size) if mode!='creative' else None\n",
        "\n",
        "        if self.mode == 'paint_by_number' and self.target is not None:\n",
        "            try:\n",
        "                quant, labels, palette = quantize_colors(self.target, n_colors=self.n_regions)\n",
        "            except Exception as e:\n",
        "                h,w,_ = self.target.shape\n",
        "                labels = np.zeros((h,w), dtype=np.int32)\n",
        "                palette = np.linspace(0,1,self.n_regions)[:,None].repeat(3,axis=1)\n",
        "                quant = palette[labels]\n",
        "            self.region_labels = labels\n",
        "            self.palette = palette\n",
        "            self.region_masks = [(self.region_labels == i).astype(np.float32)[:,:,None] for i in range(self.n_regions)]\n",
        "        elif self.mode == 'contour' and self.target is not None:\n",
        "            gray = skcolor.rgb2gray(self.target)\n",
        "            self.target_edges = edge_map(gray)\n",
        "        elif self.mode == 'stylization' and self.target is not None:\n",
        "            self.target_blur = np.array(Image.fromarray((self.target*255).astype('uint8')).filter(ImageFilter.GaussianBlur(radius=2))).astype(np.float32)/255.0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        if self.target is None:\n",
        "            self.canvas = np.ones((self.canvas_size, self.canvas_size, 3), dtype=np.float32)\n",
        "        else:\n",
        "            self.canvas = np.ones_like(self.target)\n",
        "        self.step_idx = 0\n",
        "        return self._obs()\n",
        "\n",
        "    def _obs(self):\n",
        "        if self.mode == 'creative':\n",
        "            obs = self.canvas.transpose(2,0,1).astype(np.float32)\n",
        "        else:\n",
        "            obs = np.concatenate([self.canvas, self.target], axis=2).transpose(2,0,1).astype(np.float32)\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.mode == 'paint_by_number':\n",
        "            region_norm = action[0]\n",
        "            region_id = int(np.clip(np.floor(region_norm*self.n_regions), 0, self.n_regions-1))\n",
        "            r,g,b = np.clip(action[1:4],0,1)\n",
        "            mask = self.region_masks[region_id]\n",
        "            alpha = 0.6\n",
        "            self.canvas = (1-alpha*self.mask_region_strength(mask))*self.canvas + (alpha*self.mask_region_strength(mask))*np.array([r,g,b])[None,None,:]\n",
        "            reward = self._paint_by_number_reward(region_id, r, g, b)\n",
        "        elif self.mode == 'stylization':\n",
        "            self._draw_line(action)\n",
        "            reward = self._stylization_reward()\n",
        "        elif self.mode == 'contour':\n",
        "            self._draw_line(action, thickness_scale=1.0, monochrome=True)\n",
        "            reward = self._contour_reward()\n",
        "        elif self.mode == 'creative':\n",
        "            self._draw_line(action)\n",
        "            reward = self._creative_reward()\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        self.step_idx += 1\n",
        "        done = (self.step_idx >= self.max_steps)\n",
        "        return self._obs(), float(reward), done, {}\n",
        "\n",
        "    def mask_region_strength(self, mask):\n",
        "        from scipy.ndimage import gaussian_filter\n",
        "        return gaussian_filter(mask[:,:,0], sigma=1.0)[:,:,None]\n",
        "\n",
        "    def _draw_line(self, action, thickness_scale=1.0, monochrome=False):\n",
        "        x0,y0,x1,y1,r,g,b,thickness = action\n",
        "        s = self.canvas_size\n",
        "        x0_px = int(np.clip(x0,0,1)*(s-1)); y0_px = int(np.clip(y0,0,1)*(s-1))\n",
        "        x1_px = int(np.clip(x1,0,1)*(s-1)); y1_px = int(np.clip(y1,0,1)*(s-1))\n",
        "        w = max(3, int(1 + thickness * (s//3) * thickness_scale))\n",
        "        RR = int(np.clip(r*1.5,0,1)*255)\n",
        "        GG = int(np.clip(g*1.5,0,1)*255)\n",
        "        BB = int(np.clip(b*1.5,0,1)*255)\n",
        "        col = (RR, GG, BB, 255)\n",
        "        from PIL import Image as PILImage, ImageDraw as PILDraw\n",
        "        pil = PILImage.fromarray((self.canvas*255).astype('uint8'))\n",
        "        draw = PILDraw.Draw(pil, 'RGBA')\n",
        "        if monochrome:\n",
        "            draw.line((x0_px,y0_px,x1_px,y1_px), fill=(0,0,0,255), width=w)\n",
        "        else:\n",
        "            draw.line((x0_px,y0_px,x1_px,y1_px), fill=col, width=w)\n",
        "        self.canvas = np.array(pil).astype(np.float32)/255.0\n",
        "\n",
        "    def _paint_by_number_reward(self, region_id, r,g,b): #-mse(reg_canva_color,targ_color)\n",
        "        target_region_color = self.palette[region_id]\n",
        "        canvas_region = (self.canvas * self.region_masks[region_id]).reshape(-1,3)\n",
        "        target_vals = (target_region_color[None,:] * self.region_masks[region_id].reshape(-1,1))\n",
        "        mask_flat = self.region_masks[region_id].reshape(-1)\n",
        "        if mask_flat.sum() < 1:\n",
        "            return -0.0\n",
        "        mse = np.sum(((canvas_region - target_vals)**2) * mask_flat[:,None]) / (mask_flat.sum()+1e-8)\n",
        "        return -mse\n",
        "\n",
        "    def _stylization_reward(self): #mse(reg_blur,targ_blur)\n",
        "        canvas_blur = np.array(Image.fromarray((self.canvas*255).astype('uint8')).filter(ImageFilter.GaussianBlur(radius=2))).astype(np.float32)/255.0\n",
        "        l2 = -np.mean((canvas_blur - self.target_blur)**2)\n",
        "        canvas_mean = np.mean(self.canvas.reshape(-1,3), axis=0)\n",
        "        target_mean = np.mean(self.target.reshape(-1,3), axis=0)\n",
        "        color_sim = -np.mean((canvas_mean - target_mean)**2)\n",
        "        return float(0.7*l2 + 0.3*color_sim)\n",
        "\n",
        "    def _contour_reward(self): #mse(reg_edge,tar_edg)\n",
        "        canvas_gray = skcolor.rgb2gray(np.clip(self.canvas,0,1))\n",
        "        canvas_edges = edge_map(canvas_gray)\n",
        "        mse = np.mean((canvas_edges - self.target_edges)**2)\n",
        "        return -mse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e77de175",
      "metadata": {
        "id": "e77de175"
      },
      "source": [
        "## Actor-Critic model (shared across modes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b8dc4c",
      "metadata": {
        "id": "a8b8dc4c"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch.distributions import Normal\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, in_channels=6, action_dim=8, hidden=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Flatten()  #flatten 1D vector\n",
        "        ) #CNN for img recognition and preprocessing\n",
        "\n",
        "        #use dummy image to know the output size\n",
        "        dummy = torch.zeros(1, in_channels, 32, 32)\n",
        "        conv_out = self.conv(dummy).shape[1]\n",
        "        self.shared = nn.Sequential(nn.Linear(conv_out+1, hidden), nn.ReLU())\n",
        "        self.mu = nn.Linear(hidden, action_dim)\n",
        "        self.log_std = nn.Parameter(torch.zeros(action_dim)-1.0) #tell how random action should be\n",
        "        self.value = nn.Linear(hidden,1) #gives number of dependency upon paint quality\n",
        "    #extract feature from input\n",
        "    def forward(self, x, step_frac):\n",
        "        z = self.conv(x)\n",
        "        z = torch.cat([z, step_frac.unsqueeze(1)], dim=1)\n",
        "        h = self.shared(z)\n",
        "        mu = torch.tanh(self.mu(h))\n",
        "        std = torch.exp(self.log_std) #how noisy the random action should be\n",
        "        value = self.value(h).squeeze(-1) #how good the painting is\n",
        "        return mu, std, value #mean, randomness, critic judgement\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_full_painting_gif(mode, target_path, model, device, num_strokes=120, size=128, duration=0.12):\n",
        "    from PIL import Image as PILImage\n",
        "    env = PaintEnvMulti(mode=mode, target=target_path, canvas_size=32, max_steps=num_strokes)\n",
        "    obs = env.reset()\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    # ADD BLANK FRAME FIRST\n",
        "    blank = PILImage.fromarray((env.canvas*255).astype('uint8')).resize((size,size))\n",
        "    frames.append(np.asarray(blank))\n",
        "\n",
        "    for step in range(num_strokes):\n",
        "        # BEFORE PAINT\n",
        "        before = PILImage.fromarray((env.canvas*255).astype('uint8')).resize((size,size))\n",
        "        frames.append(np.asarray(before))\n",
        "\n",
        "        # COMPUTE ACTION\n",
        "        obs_t = torch.tensor(obs).unsqueeze(0).to(device)\n",
        "        step_frac = torch.tensor([step/env.max_steps], dtype=torch.float32).to(device)\n",
        "        mu, std, _ = model(obs_t, step_frac)\n",
        "\n",
        "        action = map_action_raw_to_env(mu.detach()[0].cpu().numpy())\n",
        "\n",
        "        # APPLY STROKE\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "\n",
        "        # AFTER PAINT\n",
        "        after = PILImage.fromarray((env.canvas*255).astype('uint8')).resize((size,size))\n",
        "        frames.append(np.asarray(after))\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    outpath = f'full_paint_timelapse_{mode}.gif'\n",
        "    imageio.mimsave(outpath, frames, duration=duration)\n",
        "    print(\"Saved:\", outpath)\n",
        "    return outpath\n"
      ],
      "metadata": {
        "id": "T6N6FeooIPaS"
      },
      "id": "T6N6FeooIPaS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1636ee01",
      "metadata": {
        "id": "1636ee01"
      },
      "outputs": [],
      "source": [
        "# Training loop that accepts mode and optional target path\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import namedtuple\n",
        "from torch.distributions import Normal\n",
        "import imageio, numpy as np\n",
        "Transition = namedtuple('Transition', ['obs','step_frac','action_raw','logp','reward','done','value'])\n",
        "\n",
        "#convert raw network outputs to environment range\n",
        "def map_action_raw_to_env(a_raw):\n",
        "    a = (a_raw + 1.0) / 2.0\n",
        "    return np.clip(a, 0.0, 1.0)\n",
        "\n",
        "#samples an action from a Normal Distribution and return the sample and its log- probability\n",
        "def action_from_dist(mu, std):\n",
        "    dist = Normal(mu, std)\n",
        "    raw = dist.rsample()\n",
        "    logp = dist.log_prob(raw).sum(dim=-1)\n",
        "    return raw, logp\n",
        "\n",
        "#Main Training loop\n",
        "def train_mode(mode='paint_by_number', target_path=None, num_iterations=200, episodes_per_iter=6, max_steps=30, lr=3e-4, gamma=0.99, save_every=60):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if target_path is None and mode!='creative':\n",
        "        target = None\n",
        "    else:\n",
        "        target = target_path\n",
        "    env = PaintEnvMulti(mode=mode, target=target, canvas_size=32, max_steps=max_steps, n_regions=6)\n",
        "    in_ch = 3 if mode=='creative' else 6\n",
        "    model = ActorCritic(in_channels=in_ch, action_dim=8, hidden=128).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for it in range(1, num_iterations+1):\n",
        "        transitions = []\n",
        "        rewards = []\n",
        "        mses = []\n",
        "        for ep in range(episodes_per_iter):\n",
        "            obs = env.reset()\n",
        "            ep_reward = 0.0\n",
        "            for step in range(max_steps):\n",
        "                obs_t = torch.tensor(obs).unsqueeze(0).to(device)\n",
        "                step_frac = torch.tensor([step/max_steps], dtype=torch.float32).to(device)\n",
        "                mu, std, value = model(obs_t, step_frac)\n",
        "                raw, logp = action_from_dist(mu, std)\n",
        "                action = raw.detach().cpu().numpy()[0]\n",
        "                action_mapped = map_action_raw_to_env(action)\n",
        "                next_obs, reward, done, info = env.step(action_mapped)\n",
        "                transitions.append(Transition(obs=obs.copy(), step_frac=step/max_steps, action_raw=action, logp=logp.detach().cpu().numpy(), reward=reward, done=done, value=value.detach().cpu().numpy()))\n",
        "                obs = next_obs\n",
        "                ep_reward += reward\n",
        "                if done: break\n",
        "            rewards.append(ep_reward)\n",
        "            if mode != 'creative' and env.target is not None:\n",
        "                mses.append(np.mean((env.canvas - env.target)**2))\n",
        "        # compute returns\n",
        "        returns = []\n",
        "        R = 0.0\n",
        "        for t in reversed(range(len(transitions))):\n",
        "            R = transitions[t].reward + gamma * R * (1.0 - float(transitions[t].done))\n",
        "            returns.insert(0, R)\n",
        "        returns = torch.tensor(returns, dtype=torch.float32).to(device)\n",
        "\n",
        "        obs_batch = torch.tensor(np.stack([tr.obs for tr in transitions], axis=0)).to(device)\n",
        "        step_batch = torch.tensor([tr.step_frac for tr in transitions], dtype=torch.float32).to(device)\n",
        "        action_raw_batch = torch.tensor(np.stack([tr.action_raw for tr in transitions], axis=0)).to(device)\n",
        "        old_logp_batch = torch.tensor(np.stack([tr.logp for tr in transitions], axis=0)).to(device)\n",
        "\n",
        "        mu_b, std_b, value_b = model(obs_batch, step_batch)\n",
        "        dist = Normal(mu_b, std_b)\n",
        "        logp_b = dist.log_prob(action_raw_batch).sum(dim=-1)\n",
        "        advantages = returns - value_b.detach()\n",
        "        value_loss = F.mse_loss(value_b, returns)\n",
        "        policy_loss = -(advantages.detach() * logp_b).mean()\n",
        "        entropy_loss = -dist.entropy().sum(dim=-1).mean() * 0.01\n",
        "        loss = policy_loss + 0.5 * value_loss + entropy_loss\n",
        "\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "        if it % 10 == 0:\n",
        "            avg_r = float(np.mean(rewards))\n",
        "            avg_mse = float(np.mean(mses)) if mses else 0.0\n",
        "            print(f\"Iter {it:4d} | AvgReward {avg_r:+.4f} | AvgMSE {avg_mse:.6f} | Loss {loss.item():.4f}\")\n",
        "\n",
        "                # save demos more often (every 10 iters by default)\n",
        "        if it % 10 == 0 or it == 1:\n",
        "            frames = demo_mode_frames(env, model, device, num_strokes=max_steps, repeat_each=3, overlay_thickness=2)\n",
        "            fname = f'paint_mode_{mode}_iter{it}.gif'\n",
        "            # duration controls speed (seconds per frame). increase for slower playback.\n",
        "            imageio.mimsave(fname, frames, duration=0.22)\n",
        "            print('Saved demo:', fname)\n",
        "\n",
        "\n",
        "    print('Training finished for mode:', mode)\n",
        "    print(\"Generating final stroke-by-stroke GIF...\")\n",
        "    save_full_painting_gif(mode, target_path, model, device, num_strokes=max_steps)\n",
        "\n",
        "\n",
        "#creates stroke visible GIF\n",
        "def demo_mode_frames(env, model, device, num_strokes=30, repeat_each=2, overlay_thickness=2):\n",
        "    \"\"\"\n",
        "    Generate frames for a slow, stroke-visible GIF.\n",
        "\n",
        "    - repeat_each: how many times to repeat each frame (slows GIF).\n",
        "    - overlay_thickness: extra thickness for a visibly highlighted stroke overlay.\n",
        "    \"\"\"\n",
        "    obs = env.reset()\n",
        "    frames = []\n",
        "    from PIL import Image as PILImage, ImageDraw as PILDraw\n",
        "\n",
        "    # initial canvas and optional target\n",
        "    canvas = PILImage.fromarray((env.canvas*255).astype('uint8')).resize((128,128))\n",
        "    frames.append(np.asarray(canvas))\n",
        "\n",
        "    for step in range(num_strokes):\n",
        "        obs_t = torch.tensor(obs).unsqueeze(0).to(device)\n",
        "        step_frac = torch.tensor([step/env.max_steps], dtype=torch.float32).to(device)\n",
        "        mu, std, _ = model(obs_t, step_frac)\n",
        "\n",
        "        # use deterministic mean for demo so frames are consistent and visible\n",
        "        raw = (mu + std * torch.randn_like(mu)).detach()[0].cpu().numpy()\n",
        "        action_mapped = map_action_raw_to_env(raw)\n",
        "\n",
        "        # BEFORE stepping, compute pixel coords & color to overlay later\n",
        "        s = env.canvas_size\n",
        "        # map action_mapped expected layout:\n",
        "        # [x0, y0, x1, y1, r, g, b, thickness]\n",
        "        x0, y0, x1, y1, r, g, b, thickness = action_mapped\n",
        "        x0_px = int(np.clip(x0,0,1)*(s-1)); y0_px = int(np.clip(y0,0,1)*(s-1))\n",
        "        x1_px = int(np.clip(x1,0,1)*(s-1)); y1_px = int(np.clip(y1,0,1)*(s-1))\n",
        "        w_px = int(1 + thickness * (s//4) * 1.0)\n",
        "\n",
        "        # apply the action to the env (this updates env.canvas)\n",
        "        obs, reward, done, _ = env.step(action_mapped)\n",
        "\n",
        "        # take a snapshot of the updated canvas and resize for presentation\n",
        "        canvas = PILImage.fromarray((env.canvas*255).astype('uint8')).resize((128,128))\n",
        "\n",
        "        # create an overlay copy to highlight the most recent stroke (thicker + higher alpha)\n",
        "        vis = canvas.copy().convert('RGBA')\n",
        "        draw = PILDraw.Draw(vis)\n",
        "        # scale coords to resized canvas\n",
        "        scale = 128.0 / float(s)\n",
        "        ox0, oy0, ox1, oy1 = int(x0_px*scale), int(y0_px*scale), int(x1_px*scale), int(y1_px*scale)\n",
        "        overlay_width = max(2, int(w_px * scale * overlay_thickness))\n",
        "\n",
        "        # brighter visible color: if monochrome (contour) use black, else use stroke color\n",
        "        if env.mode == 'contour':\n",
        "            draw.line((ox0,oy0,ox1,oy1), fill=(0,0,0,255), width=overlay_width)\n",
        "        else:\n",
        "            vis_color = (int(np.clip(r,0,1)*255), int(np.clip(g,0,1)*255), int(np.clip(b,0,1)*255), 255)\n",
        "            # draw a bold semi-transparent overlay to make stroke pop\n",
        "            draw.line((ox0,oy0,ox1,oy1), fill=vis_color, width=overlay_width)\n",
        "\n",
        "        # convert back to RGB numpy array\n",
        "        frames.append(np.asarray(vis.convert('RGB')))\n",
        "\n",
        "        # repeat the last frame a few times so it shows in slow motion\n",
        "        for _ in range(repeat_each - 1):\n",
        "            frames.append(np.asarray(vis.convert('RGB')))\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # finally append the target image (if any) so viewers can compare\n",
        "    if env.target is not None:\n",
        "        target = PILImage.fromarray((env.target*255).astype('uint8')).resize((128,128))\n",
        "        frames.append(np.asarray(target))\n",
        "\n",
        "    return frames\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eddbae9",
      "metadata": {
        "id": "2eddbae9"
      },
      "source": [
        "## Run training for selected mode\n",
        "\n",
        "Set `MODE` (above) and `TARGET_IMAGE_PATH` (upload cell) then run the cell below. Example: `train_mode(mode='contour', target_path=TARGET_IMAGE_PATH, num_iterations=200)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1654d145",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1654d145",
        "outputId": "4cbe0399-6a94-49a7-c6e3-0152910f985a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running mode = contour target = penguin.png\n",
            "Saved demo: paint_mode_contour_iter1.gif\n",
            "Iter   10 | AvgReward -5.1042 | AvgMSE 0.321707 | Loss -0.3553\n",
            "Saved demo: paint_mode_contour_iter10.gif\n",
            "Iter   20 | AvgReward -4.7878 | AvgMSE 0.267949 | Loss 0.7089\n",
            "Saved demo: paint_mode_contour_iter20.gif\n",
            "Iter   30 | AvgReward -4.8739 | AvgMSE 0.256703 | Loss 1.1088\n",
            "Saved demo: paint_mode_contour_iter30.gif\n",
            "Iter   40 | AvgReward -4.8967 | AvgMSE 0.252604 | Loss -0.6901\n",
            "Saved demo: paint_mode_contour_iter40.gif\n",
            "Iter   50 | AvgReward -4.6471 | AvgMSE 0.268326 | Loss 1.7715\n",
            "Saved demo: paint_mode_contour_iter50.gif\n",
            "Iter   60 | AvgReward -4.7329 | AvgMSE 0.273923 | Loss -0.1421\n",
            "Saved demo: paint_mode_contour_iter60.gif\n",
            "Iter   70 | AvgReward -4.8385 | AvgMSE 0.285763 | Loss 0.2020\n",
            "Saved demo: paint_mode_contour_iter70.gif\n",
            "Iter   80 | AvgReward -4.7715 | AvgMSE 0.265250 | Loss 0.6219\n",
            "Saved demo: paint_mode_contour_iter80.gif\n",
            "Iter   90 | AvgReward -4.6940 | AvgMSE 0.275868 | Loss 0.9259\n",
            "Saved demo: paint_mode_contour_iter90.gif\n",
            "Iter  100 | AvgReward -4.7049 | AvgMSE 0.275773 | Loss 0.2353\n",
            "Saved demo: paint_mode_contour_iter100.gif\n",
            "Iter  110 | AvgReward -4.7762 | AvgMSE 0.273066 | Loss -1.2034\n",
            "Saved demo: paint_mode_contour_iter110.gif\n",
            "Iter  120 | AvgReward -4.7170 | AvgMSE 0.282786 | Loss -0.3242\n",
            "Saved demo: paint_mode_contour_iter120.gif\n",
            "Training finished for mode: contour\n",
            "Generating final stroke-by-stroke GIF...\n",
            "Saved: full_paint_timelapse_contour.gif\n"
          ]
        }
      ],
      "source": [
        "# Example run (edit parameters as desired). Uses MODE variable from earlier cell and uploaded TARGET_IMAGE_PATH.\n",
        "try:\n",
        "    TARGET_IMAGE_PATH\n",
        "except NameError:\n",
        "    TARGET_IMAGE_PATH = None\n",
        "\n",
        "print('Running mode =', MODE, 'target =', TARGET_IMAGE_PATH)\n",
        "train_mode(mode=MODE, target_path=TARGET_IMAGE_PATH, num_iterations=120, episodes_per_iter=6, max_steps=30, save_every=60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f918ed8",
      "metadata": {
        "id": "6f918ed8"
      },
      "source": [
        "## View generated demo GIFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8393d1f6",
      "metadata": {
        "id": "8393d1f6"
      },
      "outputs": [],
      "source": [
        "import glob, IPython.display as disp\n",
        "\n",
        "# Find normal demo GIFs\n",
        "demo_gifs = sorted(glob.glob('paint_mode_*.gif'))\n",
        "\n",
        "# Find final combined full timelapse GIF\n",
        "final_gifs = sorted(glob.glob('full_paint_timelapse_*.gif'))\n",
        "\n",
        "# Display demo GIFs\n",
        "print(\"=== Demo GIFs (Iteration Previews) ===\")\n",
        "if not demo_gifs:\n",
        "    print('No demo GIFs found yet. Run training to produce them.')\n",
        "else:\n",
        "    for g in demo_gifs:\n",
        "        print('Found:', g)\n",
        "        disp.display(disp.Image(g))\n",
        "\n",
        "# Download instructions\n",
        "print(\"\\n=== Download Instructions ===\")\n",
        "if demo_gifs:\n",
        "    print(f\"To download latest demo GIF:\\nfrom google.colab import files; files.download('{demo_gifs[-1]}')\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files; files.download('full_paint_timelapse_stylization.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KlaN_SWWrvek",
        "outputId": "742031c0-8ceb-4b8b-aaf3-34eabc4ab00e"
      },
      "id": "KlaN_SWWrvek",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51699fbd-a3de-40e7-a935-f9004c6e0f8d\", \"full_paint_timelapse_stylization.gif\", 4853)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files; files.download('paint_mode_stylization_iter90.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "42Brfa-Xr17t",
        "outputId": "c42e16c1-7030-4e1a-982e-ffa243157d10"
      },
      "id": "42Brfa-Xr17t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7cad7c1e-c986-4422-973e-79cfdea24a69\", \"paint_mode_stylization_iter90.gif\", 171377)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files; files.download('paint_mode_stylization_iter90.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "McCGEk6htVQC",
        "outputId": "214a0ef1-b1bd-4004-9382-95a339f24ffb"
      },
      "id": "McCGEk6htVQC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a3f847dc-22c0-4226-96c1-a373e092e283\", \"paint_mode_stylization_iter90.gif\", 171377)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files; files.download('full_paint_timelapse_stylization.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xx6ccLN1taQr",
        "outputId": "577f7c58-273c-48ff-c58a-885efbdbe48f"
      },
      "id": "xx6ccLN1taQr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_944809d9-9b52-4e94-9e92-c860af5b4efa\", \"full_paint_timelapse_stylization.gif\", 4853)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}